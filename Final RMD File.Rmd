---
title: "Sustainability and Freshwater Fish Production"
author: 
  - Clarissa Gallo^[American University]
  - Nicole Perez^[American University]
  - Amber Waltz^[American University]
date: "2022-01-09"
abstract: "This research study analyzes the increase of aquaculture production levels in different countries over a 60-year period. The research seeks to uncover which factors contribute to the increase in aquaculture production in a country over time, increasing sustainability within that country’s fishing industry. The following hypothesis is tested: as the production of freshwater fish increases in a country, the levels of aquaculture also increase over time. To answer the research question and to test our hypothesis, we examined several variables (types of fish, consumption of fish per capita, and carbon dioxide per capita) in relation to aquaculture production. We generated two Least Absolute Shrinkage and Selection Operator (LASSO) models, an elastic net model, and a linear regression model. The elastic net model was the most accurate, and it produced a value of .061 Root Mean Square Error (RMSE). Based on the results from the linear model, we reject our null hypothesis."
output: 
  pdf_document:
    number_sections: true
bibliography: main.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE}
## read in data

farmed <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/aquaculture-farmed-fish-production.csv')
captured_vs_farmed <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/capture-fisheries-vs-aquaculture.csv')
captured <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/capture-fishery-production.csv')
consumption <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/fish-and-seafood-consumption-per-capita.csv')
stock <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/fish-stocks-within-sustainable-levels.csv')
fishery <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/global-fishery-catch-by-sector.csv')
production <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/seafood-and-fish-production-thousand-tonnes.csv')
worldbank_gdp <- readr::read_csv('https://raw.githubusercontent.com/awaltz001/winter-inst-2022-seafood/main/data/World%20Bank%20Indicators_GDP%20Per%20Capita.csv')
worldbank_co2 <- readr::read_csv('https://raw.githubusercontent.com/awaltz001/winter-inst-2022-seafood/main/data/World%20Bank%20CO2%20Emissions%20Per%20Capita%20(mt).csv')


## load packages

library(tinytex)
library(rmarkdown)
library(tidymodels)
library(tidyverse)
library(stargazer)
library(rsample)
library(recipes)
library(glmnet)

## merge the data

wb_gdp <- worldbank_gdp %>%
  pivot_longer(
    cols = starts_with("19") | starts_with("20"),
    names_to = "Year",
    values_to = "gdp_per_capita",
    values_drop_na = TRUE
  )

wb_co2 <- worldbank_co2 %>%
  pivot_longer(
    cols = starts_with("19") | starts_with("20"),
    names_to = "Year",
    values_to = "co2_emissions_per_capita",
    values_drop_na = TRUE
  )

wb_gdp$year_only <- as.numeric(substr(wb_gdp$Year, 1,4))
wb_co2$year_only <- as.numeric(substr(wb_co2$Year, 1,4))

merge1 <- merge(x = wb_gdp,
            y = captured_vs_farmed,
            by.x = c("Country Code","year_only"),
            by.y = c("Code","Year"),
            all.x = TRUE)

df <- merge(x = wb_co2,
            y = merge1,
            by.x = c("Country Code","year_only"),
            by.y = c("Country Code","year_only"),
            all.x = TRUE)

df <- merge(x = df,
            y = consumption,
            by.x = c("Country Code","year_only"),
            by.y = c("Code","Year"),
            all.x = TRUE)

df <- merge(x = df,
            y = fishery,
            by.x = c("Country Code","year_only"),
            by.y = c("Code","Year"),
            all.x = TRUE)

df <- merge(x = df,
            y = production,
            by.x = c("Country Code","year_only"),
            by.y = c("Code","Year"),
            all.x = TRUE)


df_cleaned <- select(df, "year_only", "Country Name.x", "Country Code",
                     "co2_emissions_per_capita", "Aquaculture production (metric tons)", "Capture fisheries production (metric tons)", "Fish, Seafood- Food supply quantity (kg/capita/yr) (FAO, 2020)",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Freshwater Fish - 2761 - Production - 5510 - tonnes",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Pelagic Fish - 2763 - Production - 5510 - tonnes",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Crustaceans - 2765 - Production - 5510 - tonnes", "Artisanal (small-scale commercial)",
                     "Industrial (large-scale commercial)", "Discards", "Recreational", "Subsistence",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Cephalopods - 2766 - Production - 5510 - tonnes",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Demersal Fish - 2762 - Production - 5510 - tonnes",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Molluscs, Other - 2767 - Production - 5510 - tonnes",
                     "Commodity Balances - Livestock and Fish Primary Equivalent - Marine Fish, Other - 2764 - Production - 5510 - tonnes")

df_cleaned$co2_emissions_per_capita <- as.numeric(df_cleaned$co2_emissions_per_capita)

## clean data

df_cleaned$aquaprod <- df_cleaned$`Aquaculture production (metric tons)` 
df_cleaned$captureprod <- df_cleaned$`Capture fisheries production (metric tons)`
df_cleaned$consumption <- df_cleaned$`Fish, Seafood- Food supply quantity (kg/capita/yr) (FAO, 2020)`
df_cleaned$totalprod <- df_cleaned$aquaprod + df_cleaned$captureprod
df_cleaned$proportion_aquaprod <- df_cleaned$aquaprod / df_cleaned$totalprod
df_cleaned$country_code <- df_cleaned$`Country Code`
df_cleaned$country_name <- df_cleaned$`Country Name.x`
df_cleaned$freshwater <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Freshwater Fish - 2761 - Production - 5510 - tonnes`
df_cleaned$molluscs <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Molluscs, Other - 2767 - Production - 5510 - tonnes`
df_cleaned$pelagic <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Pelagic Fish - 2763 - Production - 5510 - tonnes`
df_cleaned$crustacean <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Crustaceans - 2765 - Production - 5510 - tonnes`
df_cleaned$cephalopods <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Cephalopods - 2766 - Production - 5510 - tonnes`
df_cleaned$marine <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Marine Fish, Other - 2764 - Production - 5510 - tonnes`
df_cleaned$demersal <- df_cleaned$`Commodity Balances - Livestock and Fish Primary Equivalent - Demersal Fish - 2762 - Production - 5510 - tonnes`
df_cleaned$artisanal <- df_cleaned$`Artisanal (small-scale commercial)`
df_cleaned$discards <- df_cleaned$Discards
df_cleaned$proportion_freshwater <- df_cleaned$freshwater/ df_cleaned$totalprod
df_cleaned$proportion_molluscs <- df_cleaned$molluscs/ df_cleaned$totalprod
df_cleaned$proportion_pelagic <- df_cleaned$pelagic/ df_cleaned$totalprod
df_cleaned$proportion_crustacean <- df_cleaned$crustacean/ df_cleaned$totalprod
df_cleaned$proportion_cephalopods <- df_cleaned$cephalopods/ df_cleaned$totalprod
df_cleaned$proportion_marine <- df_cleaned$marine/ df_cleaned$totalprod
df_cleaned$proportion_demersal <- df_cleaned$demersal/ df_cleaned$totalprod
df_cleaned$proportion_artisanal <- df_cleaned$artisanal/ df_cleaned$totalprod
df_cleaned$proportion_discards <- df_cleaned$discards/ df_cleaned$totalprod

machinedata <- select(df_cleaned, "year_only", "country_name", "proportion_aquaprod",
                      "consumption", "proportion_freshwater", "proportion_molluscs", "proportion_pelagic", "proportion_crustacean",
                      "proportion_cephalopods", "proportion_marine", "proportion_demersal",
                      "co2_emissions_per_capita", "totalprod")

machinedata$co2_emissions_per_capita <- as.numeric(machinedata$co2_emissions_per_capita)
```

```{r eval=FALSE, echo=FALSE}
# Because eval=FALSE, this chunk is not run. REMOVE REMOVE REMOVE
df <- read.csv()
```


# Introduction

In this section, we introduce the reader to the phenomenon we investigate. We describe the way in which our analysis contributes to an important intellectual debate, or how it answers a pressing political or social question. We introduce our hypotheses, data, and results. We signpost for the reader what's coming in the rest of the paper.


# Substance and Context

Here we go deeper into the intellectual debate, the political and social context of our investigation. To give the reader a clear sense of why we are writing this paper, we describe the relevant scholarly, technical, or popular literature.  We cite at least two published, peer-reviewed scholarly works. For example, we could cite @mooree20 or @moorav12, which we discussed in class.^[To cite a paper within parentheses, use, e.g., [@moore12].] We only cite others' work in our paper when it enhances the reader's understanding of what we, the authors of this paper, are doing.  We connect everything we cite to _our_ investigation; this is our original research, not a book report or an annotated bibliography.

In order to integrate citations into the References section below, we add entries into our file `main.bib`. This is a plain-text file that we edit in RStudio. We store `main.bib` in the same folder as our paper's `.Rmd` and `.pdf` files. Its entries are formatted so that they can be knit to `.pdf`; see [https://j.mp/2UzTXEZ](https://www.overleaf.com/learn/latex/Bibliography_management_with_bibtex#The_bibliography_file) for example entries for articles, books, and miscellaneous. We can get these entries automatically from Google Scholar by turning on BibTeX in the Google Scholar Settings - Bibliography Manager.

# Data and Methods
\label{section:data}

We completed this analysis with R, version 4.1.2. We relied on several elements from the tidyverse, tidymodels, rsample, recipes, and glmnet packages in our analysis. As aforementioned, we used data from the United Nations Food and Agriculture Organization (FAO) and World Bank to address our research question. We obtained this data through the R4DS Tidy Tuesday repository (Global Fishing), which featured this dataset from Our World in Data’s analysis “Fish and Overfishing” using data from FAO’s database FAOSTAT.

This dataset contains information regarding fish production and consumption by country per year, ranging from years 1960 to 2018. All fish production and consumption data, including production by fish type, is given in metric tons. Given our hypothesis that a country’s increase in freshwater fish production influences aquaculture production, we decided to include all variables from this dataset that pertained to fish type production (freshwater, molluscs, pelagic, crustacean, cephalopods, demersal, and other marine) in our model. We also included variables on fish consumption per capita and overall fish production to examine the influence that these variables may have on aquaculture production as well.

We also decided to test the influence of a demographic variable related to a country’s environmental performance to determine its correlation with the country’s improvement in implementing aquaculture. To do so, we obtained information from the World Bank’s World Development Indicators database on carbon dioxide emissions per capita to observe any influence on aquaculture levels. We merged the World Bank data to the FAO data on Country Code to avoid merging complications that may come from different spellings in the Country Name.

To focus our analysis on the relationship between a country’s share of aquaculture production and share of freshwater fish production, we converted the variables related to production by fish type and aquaculture production into proportions by dividing them by the country’s total fish production (the sum of aquaculture production and wild capture production). The total list of the thirteen variables included in our modeling follows: `r colnames(machinedata)`

All the datasets we used contained high levels of null values due to inconsistent reporting practices and differing years when aquaculture started to be measured in each country. We omitted all rows containing null data through the na.omit() function, causing a drop from 12,803 to 3,955 observations. Omitting this large quantity of rows may have impacted our results, particularly our residual; given more time, we may have pursued a different approach for treatment of `r NA` values that did not require us to drop entire rows.

We chose to implement our analysis through a machine learning model due to the high volume of variables we felt may influence an increase in aquaculture. Testing all of these variables allowed us to determine if freshwater fish production had a particularly strong influence on aquaculture production. We created three elastic net models with varying levels of $\alpha$ and $\lambda$, as well as a linear regression model. We chose to incorporate varying models to determine which had the lowest Root Mean Square Error (RMSE), indicating strongest prediction ability. Examining these elastic net models alongside a linear regression model also allowed us to understand the benefits and limitations of prioritizing the strongest predictors in our model.

To create our machine learning models, we used the recipes package to split our data into training and testing populations. We then produced a recipe from our training data by setting aquaculture as the outcome and all other variables in the machinedata data frame as predictors. We ran prep() and then bake() on the training data, set our $X$ value as the predictors from our processed training data (machinedata_train_processed), and set our $y$ value as the outcome (proportion of aquaculture production, proportion_aquaprod). We then used the glmnet() function to find the LASSO, set the $\lambda$ as one standard error, and generated our model’s coefficients using the coef() function. We used $\beta$ * $X$ to predict $\hat{y}$ for the test data, and found the residuals using $y$ - $\hat{y}$. Finally, we found the RMSE using the calculation: 

RMSE = \sqrt{\frac{1}{n}\Sigma_{i=1}^{n}{\Big(\frac{d_i -f_i}{\sigma_i}\Big)^2}}

We repeated this process on the same predictors and outcomes for a simple linear regression, a LASSO model with minimum $\lambda$ (where s = “lambda.min”), and an elastic net model with minimum $\lambda$ and $\alpha$ of 0.5. We then compared the RMSE of each model to determine that the final elastic net model that we tested had the strongest prediction performance. We used this model to find the coefficients for each of our $X$ variables and evaluated the strength and statistical significance of each coefficient. The following sections will describe our results in further detail.

If our data were `cars`, loaded in the chunk above, we could note that our data have `r nrow(cars)` observations.

# Results

Here, we explain and interpret our results. We try to learn as much as we can about our question as possible, given the data and analysis. We present our results clearly. We interpret them for the reader with precision and circumspection. We avoid making claims that are not substantiated by our data.

Note that this section may be integrated into Section \ref{section:data}, if joining the two improves the overall presentation.

Our results for the `cars` data include estimating the linear model 

$$\text{Distance}_i = \beta_0 + \beta_1 (\text{Speed}_i) + \epsilon_i.$$

```{r echo=FALSE}
# Estimate a linear model:
lm_out <- lm(dist ~ speed, data = cars)
# Extract the coefficient on speed:
cars_speed_coef <- coef(lm_out)["speed"]
```

Below we show the model estimates. The first table uses `xtable()`, the second uses `stargazer()`.

```{r echo=FALSE, message=FALSE, results='asis'}
# We can print regression tables with xtable or stargazer:
regr_table <- xtable::xtable(lm_out,
                             digits = 2,
                             caption = "Our Informative Caption")
print(regr_table, comment = FALSE)
```

```{r echo=FALSE, message=FALSE, results='asis'}
# We can print regression tables with xtable or stargazer:
stargazer::stargazer(lm_out, 
                     title = "Our Informative Title",
                     dep.var.caption = "Outcome",
                     digits = 2,
                     header = FALSE)
```

Using the `cars` data, we find that each unit of speed is associated with `r round(cars_speed_coef, 1)` more units of distance.

# Discussion

We remind the reader what this paper was about, why it was important, and what we found. We reflect on limitations of the data or methods. If we have specific advice for someone picking up where we leave off, we provide that guidance. We avoid making trite statements like "more research should be done".

# References 



